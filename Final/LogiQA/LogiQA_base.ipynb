{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Config"
      ],
      "metadata": {
        "id": "UvvX_L7eUTUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    \n",
        "    device = None\n",
        "    seed = 27\n",
        "    num_workers = 2\n",
        "    prefetch_factor = 2\n",
        "    fp16 = True\n",
        "    warm_up = 0.1\n",
        "    weight_decay = 0.01\n",
        "    train_batch_size = 1\n",
        "    eval_batch_size = 1\n",
        "    train_epochs = 20\n",
        "    gradient_accumulation_steps = 6\n",
        "    adam_epsilon= 1e-6\n",
        "    adam_betas = (0.9, 0.98)\n",
        "    learning_rate= 1e-5\n",
        "    max_grad_norm=0.0\n",
        "    writer=False\n",
        "    save_steps=2458\n",
        "    logging_steps=100\n",
        "    max_step=1000000\n",
        "\n",
        "    max_seq_length = 256\n",
        "    load_examples_num_workers = 2\n",
        "\n",
        "    # pretrained path\n",
        "    pretrained_model_name_or_path = 'roberta-base'\n",
        "    pretrained_model_name_or_path_cache = 'pretrained'\n",
        "\n",
        "    # local paths\n",
        "    train_data_path = '/content/dataset/train.txt'\n",
        "    val_data_path = '/content/dataset/val.txt'\n",
        "    test_data_path = '/content/dataset/test.txt'\n",
        "    output_path = 'content/output'\n",
        "    tensor_cache_path = 'content/tensor/'"
      ],
      "metadata": {
        "id": "3lmZffJ8US0i"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installs and Imports"
      ],
      "metadata": {
        "id": "Ed9suqZvTXaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "TgkVL4oPVmEC",
        "outputId": "f8851977-bb02-4718-a42a-354ddcc20240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgpEycrTTUu",
        "outputId": "671cbf9c-7779-4061-b10c-9eda1ddc978d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git lfs install\n",
        "# !git clone https://huggingface.co/roberta-large\n",
        "# !git clone https://huggingface.co/roberta-base"
      ],
      "metadata": {
        "id": "mJ6cpkJRTcDT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fvnUykmFTesL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "!wget https://www.dropbox.com/s/7q0eaosyd5zu5st/logiqa_dataset.zip \n",
        "# Full path of\n",
        "# the archive file\n",
        "filename = \"/content/logiqa_dataset.zip\"\n",
        " \n",
        "# Target directory\n",
        "extract_dir = \"/content/dataset\"\n",
        " \n",
        "# Format of archive file\n",
        "archive_format = \"zip\"\n",
        " \n",
        "# Unpack the archive file\n",
        "shutil.unpack_archive(filename, extract_dir, archive_format)\n",
        "print(\"Archive file unpacked successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-1aAXDxTgLc",
        "outputId": "033a5519-d55c-4fb5-a190-6c57163c99ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 02:46:59--  https://www.dropbox.com/s/7q0eaosyd5zu5st/logiqa_dataset.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/7q0eaosyd5zu5st/logiqa_dataset.zip [following]\n",
            "--2023-03-21 02:46:59--  https://www.dropbox.com/s/raw/7q0eaosyd5zu5st/logiqa_dataset.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com/cd/0/inline/B4oqDpctorRR22u0MIS2Dajc5x7v1XO0vnAyvYIJGxDRFwCJP0zAojV7U2644A7M7Tzrqx4FPk4mSrxafSTJFTqZ6bp4NmZJlT031Ysl9y-RX6RtYYiXmz9Ue8nbmeY2IREE3Q3OlpeyzRkwLkAf-BJSQOzrUE3n9TPsh5-eC-zE0A/file# [following]\n",
            "--2023-03-21 02:47:00--  https://uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com/cd/0/inline/B4oqDpctorRR22u0MIS2Dajc5x7v1XO0vnAyvYIJGxDRFwCJP0zAojV7U2644A7M7Tzrqx4FPk4mSrxafSTJFTqZ6bp4NmZJlT031Ysl9y-RX6RtYYiXmz9Ue8nbmeY2IREE3Q3OlpeyzRkwLkAf-BJSQOzrUE3n9TPsh5-eC-zE0A/file\n",
            "Resolving uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com (uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com (uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B4qu0R17Gs2kEpy__SdsGj-As67zIQELigHIcBWxy-mF-T-NK0Mz8QPlqemTLZEpTy-xHNxvXmdHEoLj8eG77TCn4LQJl32C4AVPhy3JT6zpHWMb1cFNw0FkT6-nGwnYpKTuyY2xtqh3UUyiZjCMHohyCEDZvVCXv6yW80wRjukJV2qIhCemeEJexX-_tshblAFUDPwR1QzQiS6TEDjppJK1dHxOI0Ml2AN1gJi4_l2iOXrBKsezKO6ss6IuWBA7tKWWiK3e6JJGGJXQep9OsE0tL-LSKxASAf9L2ryKovAUOmspGBm2PCqTRFierzoakFswlwByt7Ib9wqKlpnmAQqLB36PUw4-ywAiIf30BxW-4lUa8kz25tRNu-SpLVS9n-a8CXmeDiV4UcJO5hIvu8X27wg4CCbVqvhJnKRh-AdwCg/file [following]\n",
            "--2023-03-21 02:47:00--  https://uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com/cd/0/inline2/B4qu0R17Gs2kEpy__SdsGj-As67zIQELigHIcBWxy-mF-T-NK0Mz8QPlqemTLZEpTy-xHNxvXmdHEoLj8eG77TCn4LQJl32C4AVPhy3JT6zpHWMb1cFNw0FkT6-nGwnYpKTuyY2xtqh3UUyiZjCMHohyCEDZvVCXv6yW80wRjukJV2qIhCemeEJexX-_tshblAFUDPwR1QzQiS6TEDjppJK1dHxOI0Ml2AN1gJi4_l2iOXrBKsezKO6ss6IuWBA7tKWWiK3e6JJGGJXQep9OsE0tL-LSKxASAf9L2ryKovAUOmspGBm2PCqTRFierzoakFswlwByt7Ib9wqKlpnmAQqLB36PUw4-ywAiIf30BxW-4lUa8kz25tRNu-SpLVS9n-a8CXmeDiV4UcJO5hIvu8X27wg4CCbVqvhJnKRh-AdwCg/file\n",
            "Reusing existing connection to uc6a1cfae77f9abeb914ce4860a4.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2492441 (2.4M) [application/zip]\n",
            "Saving to: ‘logiqa_dataset.zip.1’\n",
            "\n",
            "logiqa_dataset.zip. 100%[===================>]   2.38M  7.48MB/s    in 0.3s    \n",
            "\n",
            "2023-03-21 02:47:01 (7.48 MB/s) - ‘logiqa_dataset.zip.1’ saved [2492441/2492441]\n",
            "\n",
            "Archive file unpacked successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset, SequentialSampler\n",
        "from torch.cuda.amp import GradScaler\n",
        "from transformers import AutoTokenizer, get_linear_schedule_with_warmup, AdamW, PreTrainedTokenizer\n",
        "from transformers.modeling_outputs import MultipleChoiceModelOutput\n",
        "from transformers.tokenization_utils_base import PaddingStrategy, TruncationStrategy\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel, RobertaConfig, RobertaLMHead\n",
        "\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "from typing import Dict, List\n",
        "from nltk import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "from abc import ABC\n",
        "\n",
        "if config.writer:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "Ymo5YM2fUhXb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Dependencies"
      ],
      "metadata": {
        "id": "bxRC3l2cUX60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(logits, labels):\n",
        "    assert logits.size()[:-1] == labels.size()\n",
        "\n",
        "    _, pred = logits.max(dim=-1)\n",
        "    true_label_num = (labels != -1).sum().item()\n",
        "    correct = (pred == labels).sum().item()\n",
        "    if true_label_num == 0:\n",
        "        return 0, 0\n",
        "    acc = correct * 1.0 / true_label_num\n",
        "    return acc, true_label_num\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        if isinstance(val, torch.Tensor):\n",
        "            val = val.item()\n",
        "        if isinstance(n, torch.Tensor):\n",
        "            n = n.item()\n",
        "\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        if self.count > 0:\n",
        "            self.avg = self.sum / self.count\n",
        "        else:\n",
        "            self.avg = 0\n",
        "\n",
        "    def save(self):\n",
        "        return {\n",
        "            'val': self.val,\n",
        "            'avg': self.avg,\n",
        "            'sum': self.sum,\n",
        "            'count': self.count\n",
        "        }\n",
        "\n",
        "    def load(self, value: dict):\n",
        "        if value is None:\n",
        "            self.reset()\n",
        "        self.val = value['val'] if 'val' in value else 0\n",
        "        self.avg = value['avg'] if 'avg' in value else 0\n",
        "        self.sum = value['sum'] if 'sum' in value else 0\n",
        "        self.count = value['count'] if 'count' in value else 0\n",
        "        \n",
        "class LogMetric(object):\n",
        "    \"\"\"\n",
        "    Record all metrics for logging.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *metric_names):\n",
        "\n",
        "        self.metrics = {\n",
        "            key: AverageMeter() for key in metric_names\n",
        "        }\n",
        "\n",
        "    def update(self, metric_name, val, n=1):\n",
        "\n",
        "        self.metrics[metric_name].update(val, n)\n",
        "\n",
        "    def reset(self, metric_name=None):\n",
        "        if metric_name is None:\n",
        "            for key in self.metrics.keys():\n",
        "                self.metrics[key].reset()\n",
        "            return\n",
        "\n",
        "        self.metrics[metric_name].reset()\n",
        "\n",
        "    def get_log(self):\n",
        "\n",
        "        log = {\n",
        "            key: self.metrics[key].avg for key in self.metrics\n",
        "        }\n",
        "        return log\n",
        "\n",
        "class LogMixin:\n",
        "    eval_metrics: LogMetric = None\n",
        "\n",
        "    def init_metric(self, *metric_names):\n",
        "        self.eval_metrics = LogMetric(*metric_names)\n",
        "\n",
        "    def get_eval_log(self, reset=False):\n",
        "        if self.eval_metrics is None:\n",
        "            print(\"The `eval_metrics` attribute hasn't been initialized.\")\n",
        "\n",
        "        results = self.eval_metrics.get_log()\n",
        "\n",
        "        _eval_metric_log = '\\t'.join([f\"{k}: {v}\" for k, v in results.items()])\n",
        "\n",
        "        if reset:\n",
        "            self.eval_metrics.reset()\n",
        "\n",
        "        return _eval_metric_log, results"
      ],
      "metadata": {
        "id": "Gc_pCNOnU7y1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "mVFy-69SVGA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaForMultipleChoice(RobertaPreTrainedModel, LogMixin, ABC):\n",
        "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
        "\n",
        "    def __init__(self, config: RobertaConfig,\n",
        "                 re_init_cls: bool = False,\n",
        "                 fs_checkpoint: bool = False,\n",
        "                 fs_checkpoint_offload_to_cpu: bool = False,\n",
        "                 fs_checkpoint_maintain_forward_counter: bool = False,\n",
        "                 freeze_encoder: bool = False,\n",
        "                 no_pooler: bool = False):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.roberta = RobertaModel(config)\n",
        "        self.lm_head = RobertaLMHead(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.re_init_cls = re_init_cls\n",
        "        if self.re_init_cls:\n",
        "            self.classifier_i = nn.Linear(config.hidden_size, 1)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
        "        self.no_pooler = no_pooler\n",
        "        self.freeze_encoder = freeze_encoder\n",
        "        print(self.freeze_encoder)\n",
        "        if freeze_encoder:\n",
        "            for param in self.roberta.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.init_metric(\"loss\", \"acc\")\n",
        "\n",
        "    @staticmethod\n",
        "    def fold_tensor(x: Tensor):\n",
        "        if x is None:\n",
        "            return x\n",
        "        return x.reshape(-1, x.size(-1))\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids: Tensor,\n",
        "            attention_mask: Tensor = None,\n",
        "            token_type_ids: Tensor = None,\n",
        "            labels: Tensor = None,\n",
        "            sentence_index: Tensor = None,\n",
        "            sentence_mask: Tensor = None,\n",
        "            sent_token_mask: Tensor = None,\n",
        "            mlm_labels: Tensor = None,\n",
        "            output_attentions=None,\n",
        "            output_hidden_states=None,\n",
        "            return_dict=None,\n",
        "    ):\n",
        "\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        num_choices = input_ids.shape[1]\n",
        "\n",
        "        input_ids = self.fold_tensor(input_ids)\n",
        "        attention_mask = self.fold_tensor(attention_mask)\n",
        "        token_type_ids = self.fold_tensor(token_type_ids)\n",
        "\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        if self.no_pooler:\n",
        "            pooled_output = outputs[0][:, 0]\n",
        "        else:\n",
        "            pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        if self.re_init_cls:\n",
        "            logits = self.classifier_i(pooled_output)\n",
        "        else:\n",
        "            logits = self.classifier(pooled_output)\n",
        "        reshaped_logits = logits.view(-1, num_choices)\n",
        "\n",
        "        choice_mask = (attention_mask.sum(dim=-1) == 0).reshape(-1, num_choices)\n",
        "        reshaped_logits = reshaped_logits + choice_mask * -10000.0\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(reshaped_logits, labels)\n",
        "\n",
        "            if mlm_labels is not None:\n",
        "                mlm_scores = self.lm_head(outputs[0])\n",
        "                mlm_loss = loss_fct(mlm_scores.reshape(-1, self.config.vocab_size), mlm_labels.reshape(-1))\n",
        "                loss += mlm_loss\n",
        "\n",
        "            if not self.training:\n",
        "                acc, true_label_num = get_accuracy(reshaped_logits, labels)\n",
        "                self.eval_metrics.update(\"acc\", val=acc, n=true_label_num)\n",
        "                self.eval_metrics.update(\"loss\", val=loss.item(), n=true_label_num)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (reshaped_logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return MultipleChoiceModelOutput(\n",
        "            loss=loss,\n",
        "            logits=reshaped_logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "VtdoNpSCTmKz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Providers"
      ],
      "metadata": {
        "id": "M0Kk_TYYVCNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sep_tokens(_tokenizer):\n",
        "    return [_tokenizer.sep_token] * (_tokenizer.max_len_single_sentence - _tokenizer.max_len_sentences_pair)\n",
        "\n",
        "\n",
        "def is_bpe(_tokenizer: PreTrainedTokenizer):\n",
        "    return _tokenizer.__class__.__name__ in [\n",
        "        \"RobertaTokenizer\",\n",
        "        \"LongformerTokenizer\",\n",
        "        \"BartTokenizer\",\n",
        "        \"RobertaTokenizerFast\",\n",
        "        \"LongformerTokenizerFast\",\n",
        "        \"BartTokenizerFast\",\n",
        "    ]\n",
        "\n",
        "\n",
        "def load_dataset(config, tokenizer, split='train'):\n",
        "    if split == 'train':\n",
        "        file_path = config.train_data_path\n",
        "    elif split == 'val':\n",
        "        file_path = config.val_data_path\n",
        "    elif split == 'test':\n",
        "        file_path = config.test_data_path\n",
        "    else:\n",
        "        raise Exception(split)\n",
        "\n",
        "    examples, features, tensors = convert_examples_into_features(file_path=file_path,\n",
        "                                                                 tokenizer=tokenizer,\n",
        "                                                                 max_seq_length=config.max_seq_length,\n",
        "                                                                 num_workers=config.load_examples_num_workers,\n",
        "                                                                suffix=split)\n",
        "    dataset = TensorDataset(*tensors)\n",
        "    return dataset, features\n",
        "\n",
        "\n",
        "def collator(batch):\n",
        "    if len(batch[0]) == 5:\n",
        "        input_ids, attention_mask, token_type_ids, labels, sentence_spans = list(zip(*batch))\n",
        "    elif len(batch[0]) == 4:\n",
        "        input_ids, attention_mask, labels, sentence_spans = list(zip(*batch))\n",
        "        token_type_ids = None\n",
        "    else:\n",
        "        raise RuntimeError()\n",
        "\n",
        "    input_ids = torch.stack(input_ids, dim=0)\n",
        "    attention_mask = torch.stack(attention_mask, dim=0)\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "    sentence_spans = torch.stack(sentence_spans, dim=0)\n",
        "\n",
        "    batch, option_num, _, _ = sentence_spans.size()\n",
        "    # [batch, option_num, max_sent_num]\n",
        "    max_sent_len = (sentence_spans[:, :, :, 1] - sentence_spans[:, :, :, 0]).max().item()\n",
        "    # [batch, option_num, max_sent_num]\n",
        "    sent_mask = (sentence_spans[:, :, :, 0] != -1)\n",
        "    # [batch, option_num]\n",
        "    sent_num = sent_mask.sum(dim=2)\n",
        "    b_max_sent_num = sent_num.max().item()\n",
        "    sentence_spans = sentence_spans[:, :, :b_max_sent_num]\n",
        "    sent_mask = sent_mask[:, :, :b_max_sent_num]\n",
        "\n",
        "    sentence_index = torch.zeros(batch, option_num, b_max_sent_num, max_sent_len, dtype=torch.long)\n",
        "    sent_token_mask = torch.zeros(batch, option_num, b_max_sent_num, max_sent_len, dtype=torch.long)\n",
        "    for b_id, b_spans in enumerate(sentence_spans):\n",
        "        for op_id, op_spans in enumerate(b_spans):\n",
        "            for sent_id, span in enumerate(op_spans):\n",
        "                s, e = span[0].item(), span[1].item()\n",
        "                if s == -1:\n",
        "                    break\n",
        "                _len = e - s\n",
        "                sentence_index[b_id, op_id, sent_id, :_len] = torch.arange(s, e, dtype=torch.long)\n",
        "                sent_token_mask[b_id, op_id, sent_id, :_len] = 1\n",
        "\n",
        "    outputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels,\n",
        "        \"sentence_index\": sentence_index,\n",
        "        \"sentence_mask\": sent_mask,\n",
        "        \"sent_token_mask\": sent_token_mask\n",
        "    }\n",
        "    if token_type_ids is not None:\n",
        "        outputs[\"token_type_ids\"] = torch.stack(token_type_ids, dim=0)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def read_examples(file_path: str):\n",
        "    LOGIQA_LABEL_TO_ID = {\"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3}\n",
        "    LOGIQA_ID_TO_LABEL = {0: \"a\", 1: \"b\", 2: \"c\", 3: \"d\"}\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as out:\n",
        "            data = out.read().split(\"\\n\\n\")\n",
        "    contexts_list = []\n",
        "    questions_list = []\n",
        "    answers_list = []\n",
        "    labels_list = []\n",
        "    examples = []\n",
        "\n",
        "    for i in data:\n",
        "        tmp_splited_i = i.split(\"\\n\")\n",
        "        contexts_list.append(tmp_splited_i[1])\n",
        "        questions_list.append(tmp_splited_i[2])\n",
        "        answers_list.append(\n",
        "            [tmp_splited_i[3], tmp_splited_i[4], tmp_splited_i[5], tmp_splited_i[6]]\n",
        "        )\n",
        "        labels_list.append(LOGIQA_LABEL_TO_ID[tmp_splited_i[0]])\n",
        "\n",
        "\n",
        "    for i in range(len(contexts_list)):\n",
        "        examples.append({\"context\": contexts_list[i],\n",
        "                    \"question\": questions_list[i],\n",
        "                    \"options\": answers_list[i],\n",
        "                    \"label\": labels_list[i]})\n",
        "  \n",
        "\n",
        "\n",
        "    print(f\"{len(examples)} examples are loaded from {file_path}.\")\n",
        "    return examples\n",
        "\n",
        "\n",
        "def _convert_example_to_features(example, tokenizer, max_seq_length):\n",
        "    context = example[\"context\"]\n",
        "    question = example[\"question\"]\n",
        "    context_sentences = [sent for sent in sent_tokenize(context) if sent]\n",
        "\n",
        "    context_tokens = []\n",
        "    for _sent_id, _sent in enumerate(context_sentences):\n",
        "        _sent_tokens = tokenizer.tokenize(_sent)\n",
        "        context_tokens.extend([(_sent_id, _tok) for _tok in _sent_tokens])\n",
        "\n",
        "    _q_sent_id_offset = len(context_sentences)\n",
        "    question_tokens = [(_q_sent_id_offset, _tok) for _tok in tokenizer.tokenize(question)]\n",
        "\n",
        "    features = []\n",
        "    for option in example[\"options\"]:\n",
        "        sep_tokens = get_sep_tokens(tokenizer)\n",
        "        _op_sent_id_offset = _q_sent_id_offset + 1\n",
        "        opt_tokens = [(_op_sent_id_offset, _tok) for _tok in tokenizer.tokenize(option)]\n",
        "\n",
        "        lens_to_remove = len(context_tokens) + len(question_tokens) + len(opt_tokens) + len(sep_tokens) + (\n",
        "                tokenizer.model_max_length - tokenizer.max_len_sentences_pair) - max_seq_length\n",
        "\n",
        "        tru_c_tokens, tru_q_o_tokens, _ = tokenizer.truncate_sequences(context_tokens,\n",
        "                                                                       question_tokens + sep_tokens + opt_tokens,\n",
        "                                                                       num_tokens_to_remove=lens_to_remove,\n",
        "                                                                       truncation_strategy=TruncationStrategy.LONGEST_FIRST)\n",
        "\n",
        "        c_tokens, q_op_tokens = [], []\n",
        "        sent_id_map = Counter()\n",
        "\n",
        "        for _sent_id, _tok in tru_c_tokens:\n",
        "            sent_id_map[_sent_id] += 1\n",
        "            c_tokens.append(_tok)\n",
        "\n",
        "        for _tok in tru_q_o_tokens:\n",
        "            if isinstance(_tok, tuple):\n",
        "                _sent_id, _tok = _tok\n",
        "                q_op_tokens.append(_tok)\n",
        "                sent_id_map[_sent_id] += 1\n",
        "            elif isinstance(_tok, str):\n",
        "                q_op_tokens.append(_tok)\n",
        "            else:\n",
        "                raise RuntimeError(_tok)\n",
        "\n",
        "        sent_span_offset = 1\n",
        "        sent_spans = []\n",
        "        for i in range(len(context_sentences) + 2):\n",
        "            if i == _q_sent_id_offset or i == _op_sent_id_offset:\n",
        "                sent_span_offset += (tokenizer.max_len_single_sentence - tokenizer.max_len_sentences_pair)\n",
        "            if i in sent_id_map:\n",
        "                _cur_len = sent_id_map.pop(i)\n",
        "                sent_spans.append((sent_span_offset, sent_span_offset + _cur_len))\n",
        "                sent_span_offset += _cur_len\n",
        "        assert not sent_id_map\n",
        "\n",
        "        tokenizer_outputs = tokenizer(tokenizer.convert_tokens_to_string(c_tokens),\n",
        "                                      text_pair=tokenizer.convert_tokens_to_string(q_op_tokens),\n",
        "                                      padding=PaddingStrategy.MAX_LENGTH,\n",
        "                                      max_length=max_seq_length)\n",
        "        assert len(tokenizer_outputs[\"input_ids\"]) == max_seq_length, (\n",
        "        len(c_tokens), len(q_op_tokens), len(tokenizer_outputs[\"input_ids\"]))\n",
        "        features.append({\n",
        "            \"input_ids\": tokenizer_outputs[\"input_ids\"],\n",
        "            \"attention_mask\": tokenizer_outputs[\"attention_mask\"],\n",
        "            \"token_type_ids\": tokenizer_outputs[\"token_type_ids\"] if \"token_type_ids\" in tokenizer_outputs else None,\n",
        "            \"sentence_spans\": sent_spans,\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"features\": features,\n",
        "        \"label\": example[\"label\"]\n",
        "    }\n",
        "\n",
        "\n",
        "def _data_to_tensors(features):\n",
        "    data_num = len(features)\n",
        "    option_num = len(features[0][\"features\"])\n",
        "\n",
        "    input_ids = torch.tensor([[op[\"input_ids\"] for op in f[\"features\"]] for f in features])\n",
        "    attention_mask = torch.tensor([[op[\"attention_mask\"] for op in f[\"features\"]] for f in features], dtype=torch.long)\n",
        "    if features[0][\"features\"][0][\"token_type_ids\"] is not None:\n",
        "        token_type_ids = torch.tensor([[op[\"token_type_ids\"] for op in f[\"features\"]] for f in features],\n",
        "                                      dtype=torch.long)\n",
        "    else:\n",
        "        token_type_ids = None\n",
        "    labels = torch.tensor([f[\"label\"] for f in features], dtype=torch.long)\n",
        "\n",
        "    # List[List[List[Tuple[int, int]]]]\n",
        "    sentence_spans_ls = [[op[\"sentence_spans\"] for op in f[\"features\"]] for f in features]\n",
        "    max_sent_num = 0\n",
        "    for f in sentence_spans_ls:\n",
        "        f_max_sent_num = max(map(len, f))\n",
        "        max_sent_num = max(f_max_sent_num, max_sent_num)\n",
        "\n",
        "    sentence_spans = torch.zeros(data_num, option_num, max_sent_num, 2, dtype=torch.long).fill_(-1)\n",
        "    for f_id, f in enumerate(sentence_spans_ls):\n",
        "        for op_id, op in enumerate(f):\n",
        "            f_op_sent_num = len(op)\n",
        "            sentence_spans[f_id, op_id, :f_op_sent_num] = torch.tensor(op, dtype=torch.long)\n",
        "\n",
        "    if token_type_ids is not None:\n",
        "        return input_ids, attention_mask, token_type_ids, labels, sentence_spans\n",
        "    else:\n",
        "        return input_ids, attention_mask, labels, sentence_spans\n",
        "\n",
        "\n",
        "def convert_examples_into_features(file_path, tokenizer, max_seq_length, num_workers = 16, suffix=''):\n",
        "    tokenizer_name = tokenizer.__class__.__name__\n",
        "    tokenizer_name = tokenizer_name.replace('TokenizerFast', '')\n",
        "    tokenizer_name = tokenizer_name.replace('Tokenizer', '').lower()\n",
        "\n",
        "    file_suffix = f\"{tokenizer_name}_{max_seq_length}_{suffix}\"\n",
        "    cached_file_path = config.tensor_cache_path + file_suffix\n",
        "\n",
        "    if os.path.exists(cached_file_path):\n",
        "        print(f\"Loading cached file from {cached_file_path}\")\n",
        "        examples, features, tensors = torch.load(cached_file_path)\n",
        "        return examples, features, tensors\n",
        "\n",
        "    examples = read_examples(file_path)\n",
        "\n",
        "    with Pool(num_workers) as p:\n",
        "        _annotate = partial(_convert_example_to_features, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "        features = list(tqdm(\n",
        "            p.imap(_annotate, examples, chunksize=32),\n",
        "            total=len(examples),\n",
        "            desc='converting examples to features:'\n",
        "        ))\n",
        "\n",
        "    print(\"Transform features into tensors...\")\n",
        "    tensors = _data_to_tensors(features)\n",
        "\n",
        "    print(f\"Saving processed features into {cached_file_path}.\")\n",
        "    if not os.path.exists(config.tensor_cache_path):\n",
        "        os.makedirs(config.tensor_cache_path)\n",
        "    torch.save((examples, features, tensors), cached_file_path)\n",
        "\n",
        "    return examples, features, tensors"
      ],
      "metadata": {
        "id": "ldBid4qYT116"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_and_backward(model, inputs, config, scaler):\n",
        "    if config.fp16 and scaler:\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[\"loss\"]\n",
        "    else:\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[\"loss\"]\n",
        "\n",
        "    if config.gradient_accumulation_steps > 1:\n",
        "        loss = loss / config.gradient_accumulation_steps\n",
        "\n",
        "    if scaler:\n",
        "        scaler.scale(loss).backward()\n",
        "    else:\n",
        "        loss.backward()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def batch_to_device(batch, device):\n",
        "    batch_on_device = {}\n",
        "    for k, v in batch.items():\n",
        "        batch_on_device[k] = v.to(device)\n",
        "    return batch_on_device\n",
        "\n",
        "def train_model(config, train_dataset,val_dataset, model, tokenizer, start_global_step):\n",
        "    output_path_split = config.output_path.split('/')\n",
        "    log_dir = '/'.join([output_path_split[0], 'runs'] + output_path_split[1:])\n",
        "    if config.writer:\n",
        "        writer = SummaryWriter(log_dir=log_dir)\n",
        "    else:\n",
        "        writer = None\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=config.train_batch_size,\n",
        "                              collate_fn=collator,\n",
        "                              num_workers=config.num_workers,\n",
        "                              pin_memory=True,\n",
        "                              prefetch_factor=config.prefetch_factor)\n",
        "    \n",
        "    val_loader = DataLoader(dataset=val_dataset,\n",
        "                              sampler=RandomSampler(val_dataset),\n",
        "                              batch_size=config.train_batch_size,\n",
        "                              collate_fn=collator,\n",
        "                              num_workers=config.num_workers,\n",
        "                              pin_memory=True,\n",
        "                              prefetch_factor=config.prefetch_factor)\n",
        "\n",
        "    no_decay = ['bias', 'LayerNorm.weight', 'layer_norm.weight']\n",
        "    grouped_parameters = [\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters() if\n",
        "                       (not any(nd in n for nd in no_decay)) and p.requires_grad],\n",
        "            'weight_decay': config.weight_decay\n",
        "        },\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters() if (any(nd in n for nd in no_decay)) and p.requires_grad],\n",
        "            'weight_decay': 0.0\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    total_steps = len(train_loader) // config.gradient_accumulation_steps * config.train_epochs\n",
        "\n",
        "    optimizer = AdamW(grouped_parameters,\n",
        "                      lr=config.learning_rate,\n",
        "                      eps=config.adam_epsilon,\n",
        "                      betas=config.adam_betas)\n",
        "    import transformers\n",
        "    scheduler = transformers.get_scheduler(\n",
        "                        \"linear\",    # Create a schedule with a learning rate that decreases linearly \n",
        "                                     # from the initial learning rate set in the optimizer to 0.\n",
        "                        optimizer = optimizer,\n",
        "                        num_warmup_steps = 0,\n",
        "                        num_training_steps = total_steps)\n",
        "\n",
        "    if config.fp16 and config.device.type == 'cuda':\n",
        "        scaler = GradScaler()\n",
        "    else:\n",
        "        scaler = None\n",
        "    print(optimizer)\n",
        "    print(\"-- Start Training --\")\n",
        "    print(\"  Num examples = \", len(train_dataset))\n",
        "    print(\"  Num Epochs = \", config.train_epochs)\n",
        "    print(\"  Batch size = \", config.train_batch_size)\n",
        "    print(\"  Gradient Accumulation steps = \", config.gradient_accumulation_steps)\n",
        "    print(\"  Total optimization steps = \", total_steps)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    random.seed(config.seed)\n",
        "    np.random.seed(config.seed)\n",
        "    torch.manual_seed(config.seed)\n",
        "    train_loss_array = []\n",
        "    val_loss_array = []\n",
        "    val_acc_array = []\n",
        "    for epoch in range(config.train_epochs):\n",
        "        for step, batch in enumerate(train_loader):\n",
        "\n",
        "            if global_step < start_global_step:\n",
        "                if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "                    scheduler.step()\n",
        "                    global_step += 1\n",
        "                continue\n",
        "                \n",
        "            model.train()\n",
        "            batch = batch_to_device(batch, config.device)\n",
        "            \n",
        "            loss = forward_and_backward(model, batch, config, scaler)\n",
        "            tr_loss += loss\n",
        "\n",
        "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
        "\n",
        "                if scaler:\n",
        "                    scaler.unscale_(optimizer)\n",
        "\n",
        "                if config.max_grad_norm:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "\n",
        "                if scaler:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    optimizer.step()\n",
        "\n",
        "                scheduler.step()\n",
        "                model.zero_grad(set_to_none=True)\n",
        "                global_step += 1\n",
        "\n",
        "                \n",
        "                train_loss_array.append((tr_loss - logging_loss))\n",
        "                if config.logging_steps > 0 and global_step % config.logging_steps == 0:\n",
        "                    if config.writer:\n",
        "                        writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
        "                        writer.add_scalar('loss', (tr_loss - logging_loss) / config.logging_steps, global_step)\n",
        "                    else:\n",
        "                        print('gb_step={}, loss={}'.format(global_step, (tr_loss - logging_loss) / config.logging_steps))\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if config.save_steps > 0 and global_step % config.save_steps == 0:\n",
        "                    output_dir = os.path.join(config.output_path, 'checkpoint-{}'.format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                        \n",
        "                    model.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "                    print(\"Saving model checkpoint to \", output_dir)\n",
        "                    \n",
        "            if global_step >= config.max_step:\n",
        "                break\n",
        "        \n",
        "        if global_step >= config.max_step:\n",
        "            break\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        num_val_steps = 0\n",
        "        correct_predictions = 0.0\n",
        "        pred_list = []\n",
        "        prob_list = []  \n",
        "        \n",
        "        for val_batch in (val_loader):\n",
        "            batch = batch_to_device(val_batch, config.device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "              with torch.no_grad():\n",
        "                  outputs = model(**batch)\n",
        "                  val_loss += outputs.loss.item()\n",
        "                  num_val_steps = num_val_steps +1\n",
        "                  predictions = outputs.logits.argmax(dim=-1)\n",
        "                  targets = batch[\"labels\"]\n",
        "                  correct_predictions += (predictions == targets).sum().item()\n",
        "        val_loss /= num_val_steps\n",
        "        val_acc = (correct_predictions / len(val_loader))\n",
        "        val_loss_array.append(val_loss)\n",
        "        val_acc_array.append(val_acc)\n",
        "        print(\"VAL ACCURACY\",val_acc)\n",
        "        print(\"val_loss\",val_loss)\n",
        "    import json\n",
        "    json.dumps(val_loss_array)\n",
        "    json.dumps(val_acc_array)\n",
        "    json.dumps(train_loss_array)\n",
        "    return global_step, tr_loss / global_step"
      ],
      "metadata": {
        "id": "maPERhQHVLzk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main(start_global_step=0):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    config.device = device\n",
        "    \n",
        "    random.seed(config.seed)\n",
        "    np.random.seed(config.seed)\n",
        "    torch.manual_seed(config.seed)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.pretrained_model_name_or_path, cache_dir=config.pretrained_model_name_or_path_cache)\n",
        "    model = RobertaForMultipleChoice.from_pretrained(config.pretrained_model_name_or_path, cache_dir=config.pretrained_model_name_or_path_cache)\n",
        "\n",
        "    model.to(config.device)\n",
        "\n",
        "    train_dataset, features = load_dataset(config, tokenizer=tokenizer, split='train')\n",
        "    val_dataset, features_val = load_dataset(config, tokenizer=tokenizer, split='val')\n",
        "    \n",
        "    step, loss = train_model(config, train_dataset, val_dataset, model, tokenizer, start_global_step)\n",
        "    print('Train finished, step: {}, loss: {}'.format(step, loss))"
      ],
      "metadata": {
        "id": "lLnlFq5YVOmf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_main()"
      ],
      "metadata": {
        "id": "j1u7-3agVWtm",
        "outputId": "12ed7759-0473-4010-c806-f2266717c3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'lm_head.decoder.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cached file from content/tensor/roberta_256_train\n",
            "Loading cached file from content/tensor/roberta_256_val\n",
            "AdamW (\n",
            "Parameter Group 0\n",
            "    betas: (0.9, 0.98)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0.01\n",
            "\n",
            "Parameter Group 1\n",
            "    betas: (0.9, 0.98)\n",
            "    correct_bias: True\n",
            "    eps: 1e-06\n",
            "    initial_lr: 1e-05\n",
            "    lr: 1e-05\n",
            "    weight_decay: 0.0\n",
            ")\n",
            "-- Start Training --\n",
            "  Num examples =  7376\n",
            "  Num Epochs =  20\n",
            "  Batch size =  1\n",
            "  Gradient Accumulation steps =  6\n",
            "  Total optimization steps =  24580\n",
            "gb_step=100, loss=1.389265713095665\n",
            "gb_step=200, loss=1.3877169227600097\n",
            "gb_step=300, loss=1.3841680109500885\n",
            "gb_step=400, loss=1.3874338544905185\n",
            "gb_step=500, loss=1.384838895201683\n",
            "gb_step=600, loss=1.3825883962213994\n",
            "gb_step=700, loss=1.3872758902609348\n",
            "gb_step=800, loss=1.380693523287773\n",
            "gb_step=900, loss=1.390176800340414\n",
            "gb_step=1000, loss=1.3874616779386997\n",
            "gb_step=1100, loss=1.3891694951057434\n",
            "gb_step=1200, loss=1.3865099519491195\n",
            "VAL ACCURACY 0.25960061443932414\n",
            "val_loss 1.3714568312816355\n",
            "gb_step=1300, loss=1.389889216721058\n",
            "gb_step=1400, loss=1.3829479591548444\n",
            "gb_step=1500, loss=1.3867255902290345\n",
            "gb_step=1600, loss=1.376322414726019\n",
            "gb_step=1700, loss=1.3713395403325557\n",
            "gb_step=1800, loss=1.3908742998540402\n",
            "gb_step=1900, loss=1.3732952784001826\n",
            "gb_step=2000, loss=1.3779197123646736\n",
            "gb_step=2100, loss=1.3740377733111382\n",
            "gb_step=2200, loss=1.373879593461752\n",
            "gb_step=2300, loss=1.3578238497674464\n",
            "gb_step=2400, loss=1.3483596509695053\n",
            "Saving model checkpoint to  content/output/checkpoint-2458\n",
            "VAL ACCURACY 0.3456221198156682\n",
            "val_loss 1.3529216738706726\n",
            "gb_step=2500, loss=1.3616341604292392\n",
            "gb_step=2600, loss=1.341036911830306\n",
            "gb_step=2700, loss=1.3466271121799946\n",
            "gb_step=2800, loss=1.3323323928564788\n",
            "gb_step=2900, loss=1.337808523401618\n",
            "gb_step=3000, loss=1.3159756730496883\n",
            "gb_step=3100, loss=1.3198177552595736\n",
            "gb_step=3200, loss=1.2988749403879047\n",
            "gb_step=3300, loss=1.3149647151306272\n",
            "gb_step=3400, loss=1.3025684650242328\n",
            "gb_step=3500, loss=1.3126049237698316\n",
            "gb_step=3600, loss=1.3159180195629596\n",
            "VAL ACCURACY 0.32872503840245776\n",
            "val_loss 1.3455590385079568\n",
            "gb_step=3700, loss=1.3089313899353145\n",
            "gb_step=3800, loss=1.231885651741177\n",
            "gb_step=3900, loss=1.2165409923903645\n",
            "gb_step=4000, loss=1.213538103122264\n",
            "gb_step=4100, loss=1.1689314501173795\n",
            "gb_step=4200, loss=1.146867175102234\n",
            "gb_step=4300, loss=1.1519816821627318\n",
            "gb_step=4400, loss=1.2282417782768607\n",
            "gb_step=4500, loss=1.1747653259895743\n",
            "gb_step=4600, loss=1.218961408175528\n",
            "gb_step=4700, loss=1.1577556434646248\n",
            "gb_step=4800, loss=1.162947762021795\n",
            "gb_step=4900, loss=1.1848890387825668\n",
            "Saving model checkpoint to  content/output/checkpoint-4916\n",
            "VAL ACCURACY 0.3425499231950845\n",
            "val_loss 1.4032035649234798\n",
            "gb_step=5000, loss=1.0484502070676536\n",
            "gb_step=5100, loss=0.9715692026051692\n",
            "gb_step=5200, loss=1.0557222085166722\n",
            "gb_step=5300, loss=1.0101493656495586\n",
            "gb_step=5400, loss=0.9189072563126683\n",
            "gb_step=5500, loss=0.9729650678951294\n",
            "gb_step=5600, loss=1.030686024017632\n",
            "gb_step=5700, loss=0.9531972415256313\n",
            "gb_step=5800, loss=0.9755381579394452\n",
            "gb_step=5900, loss=1.0329965801606886\n",
            "gb_step=6000, loss=0.9761022433126345\n",
            "gb_step=6100, loss=0.9643402239627903\n",
            "VAL ACCURACY 0.31797235023041476\n",
            "val_loss 1.5486697757519359\n",
            "gb_step=6200, loss=0.8973848333093337\n",
            "gb_step=6300, loss=0.6601913907214475\n",
            "gb_step=6400, loss=0.7477331937731652\n",
            "gb_step=6500, loss=0.7161109966493677\n",
            "gb_step=6600, loss=0.7644399799880921\n",
            "gb_step=6700, loss=0.7367995801669894\n",
            "gb_step=6800, loss=0.7706485682865605\n",
            "gb_step=6900, loss=0.7284424529137322\n",
            "gb_step=7000, loss=0.8095462979434523\n",
            "gb_step=7100, loss=0.7350689049507492\n",
            "gb_step=7200, loss=0.8196087995910785\n",
            "gb_step=7300, loss=0.750632748969947\n",
            "Saving model checkpoint to  content/output/checkpoint-7374\n",
            "VAL ACCURACY 0.31336405529953915\n",
            "val_loss 1.8105044391440062\n",
            "gb_step=7400, loss=0.6958215471100994\n",
            "gb_step=7500, loss=0.5114529129559378\n",
            "gb_step=7600, loss=0.5158858543337556\n",
            "gb_step=7700, loss=0.47837754813230277\n",
            "gb_step=7800, loss=0.4379684809051287\n",
            "gb_step=7900, loss=0.516975384406669\n",
            "gb_step=8000, loss=0.59360427935002\n",
            "gb_step=8100, loss=0.5047629058490566\n",
            "gb_step=8200, loss=0.621960280848707\n",
            "gb_step=8300, loss=0.5327615116092056\n",
            "gb_step=8400, loss=0.5822336693989019\n",
            "gb_step=8500, loss=0.5638598001792707\n",
            "gb_step=8600, loss=0.5537367810316937\n",
            "VAL ACCURACY 0.3425499231950845\n",
            "val_loss 2.0108855898429807\n",
            "gb_step=8700, loss=0.3788699617070961\n",
            "gb_step=8800, loss=0.3373104282581153\n",
            "gb_step=8900, loss=0.41365459822900447\n",
            "gb_step=9000, loss=0.3964814275686513\n",
            "gb_step=9100, loss=0.38963932299051524\n",
            "gb_step=9200, loss=0.3390806252725451\n",
            "gb_step=9300, loss=0.3872450303466576\n",
            "gb_step=9400, loss=0.36943599712370995\n",
            "gb_step=9500, loss=0.3555178102751961\n",
            "gb_step=9600, loss=0.3962315575047978\n",
            "gb_step=9700, loss=0.399475745187101\n",
            "gb_step=9800, loss=0.38981066700687733\n",
            "Saving model checkpoint to  content/output/checkpoint-9832\n",
            "VAL ACCURACY 0.3333333333333333\n",
            "val_loss 2.3234608710982894\n",
            "gb_step=9900, loss=0.2880493075438972\n",
            "gb_step=10000, loss=0.3258530613845869\n",
            "gb_step=10100, loss=0.27679396255489336\n",
            "gb_step=10200, loss=0.28706911027198656\n",
            "gb_step=10300, loss=0.271625086157037\n",
            "gb_step=10400, loss=0.2658427182522246\n",
            "gb_step=10500, loss=0.30933278680733567\n",
            "gb_step=10600, loss=0.27303062795594085\n",
            "gb_step=10700, loss=0.30611564761029514\n",
            "gb_step=10800, loss=0.372660740992942\n",
            "gb_step=10900, loss=0.3209889958426902\n",
            "gb_step=11000, loss=0.26034592681829966\n",
            "VAL ACCURACY 0.30414746543778803\n",
            "val_loss 2.4938649996459197\n",
            "gb_step=11100, loss=0.281607813150149\n",
            "gb_step=11200, loss=0.22828089535703838\n",
            "gb_step=11300, loss=0.25428868675135163\n",
            "gb_step=11400, loss=0.22279848346694053\n",
            "gb_step=11500, loss=0.22224466008390664\n",
            "gb_step=11600, loss=0.19856698813975526\n",
            "gb_step=11700, loss=0.23718921265210155\n",
            "gb_step=11800, loss=0.22359018949498932\n",
            "gb_step=11900, loss=0.2592076336500941\n",
            "gb_step=12000, loss=0.23058029992171214\n",
            "gb_step=12100, loss=0.22129970149904693\n",
            "gb_step=12200, loss=0.23643107171657904\n",
            "Saving model checkpoint to  content/output/checkpoint-12290\n",
            "VAL ACCURACY 0.3379416282642089\n",
            "val_loss 2.8202226613876085\n",
            "gb_step=12300, loss=0.24467433779660497\n",
            "gb_step=12400, loss=0.1652428167189646\n",
            "gb_step=12500, loss=0.15995904659524968\n",
            "gb_step=12600, loss=0.1667348925202532\n",
            "gb_step=12700, loss=0.1908167089381095\n",
            "gb_step=12800, loss=0.18200258170729286\n",
            "gb_step=12900, loss=0.19541228291016524\n",
            "gb_step=13000, loss=0.19767953361804758\n",
            "gb_step=13100, loss=0.18519496886250636\n",
            "gb_step=13200, loss=0.2122158981305256\n",
            "gb_step=13300, loss=0.19439544765247774\n",
            "gb_step=13400, loss=0.18748505444171315\n",
            "gb_step=13500, loss=0.16278166390577098\n",
            "VAL ACCURACY 0.31797235023041476\n",
            "val_loss 2.882613446648765\n",
            "gb_step=13600, loss=0.16255950450688034\n",
            "gb_step=13700, loss=0.1778804155092621\n",
            "gb_step=13800, loss=0.1369883883552211\n",
            "gb_step=13900, loss=0.12798407589245472\n",
            "gb_step=14000, loss=0.14911772736408238\n",
            "gb_step=14100, loss=0.17047015404486957\n",
            "gb_step=14200, loss=0.11349577750705066\n",
            "gb_step=14300, loss=0.12908116831282312\n",
            "gb_step=14400, loss=0.17491107164327332\n",
            "gb_step=14500, loss=0.14511505750948345\n",
            "gb_step=14600, loss=0.10633359470206415\n",
            "gb_step=14700, loss=0.1499609521601087\n",
            "Saving model checkpoint to  content/output/checkpoint-14748\n",
            "VAL ACCURACY 0.32565284178187404\n",
            "val_loss 2.990597109039549\n",
            "gb_step=14800, loss=0.1377496003080705\n",
            "gb_step=14900, loss=0.12075691953483329\n",
            "gb_step=15000, loss=0.13270900465655358\n",
            "gb_step=15100, loss=0.12606492691686072\n",
            "gb_step=15200, loss=0.15143615322718687\n",
            "gb_step=15300, loss=0.12346325267013526\n",
            "gb_step=15400, loss=0.15726340895002067\n",
            "gb_step=15500, loss=0.18173587042427244\n",
            "gb_step=15600, loss=0.13249140251040445\n",
            "gb_step=15700, loss=0.12782319111707693\n",
            "gb_step=15800, loss=0.12047838738153586\n",
            "gb_step=15900, loss=0.15643868529472457\n",
            "VAL ACCURACY 0.3348694316436252\n",
            "val_loss 3.216211575386494\n",
            "gb_step=16000, loss=0.11099218047838803\n",
            "gb_step=16100, loss=0.08303661180500058\n",
            "gb_step=16200, loss=0.07853272341186311\n",
            "gb_step=16300, loss=0.08029841091252819\n",
            "gb_step=16400, loss=0.12316534657913508\n",
            "gb_step=16500, loss=0.10324108749720835\n",
            "gb_step=16600, loss=0.07611226142851592\n",
            "gb_step=16700, loss=0.1069739321533234\n",
            "gb_step=16800, loss=0.07456701557044652\n",
            "gb_step=16900, loss=0.10950684130084483\n",
            "gb_step=17000, loss=0.1339000367807057\n",
            "gb_step=17100, loss=0.11047268881446143\n",
            "gb_step=17200, loss=0.14513124494125804\n",
            "Saving model checkpoint to  content/output/checkpoint-17206\n",
            "VAL ACCURACY 0.3333333333333333\n",
            "val_loss 3.221747525882249\n",
            "gb_step=17300, loss=0.07596934469549524\n",
            "gb_step=17400, loss=0.11567926686680949\n",
            "gb_step=17500, loss=0.11936799433891793\n",
            "gb_step=17600, loss=0.10099927078072142\n",
            "gb_step=17700, loss=0.09409151646297687\n",
            "gb_step=17800, loss=0.07853555802448682\n",
            "gb_step=17900, loss=0.07646715060784118\n",
            "gb_step=18000, loss=0.10531192895947243\n",
            "gb_step=18100, loss=0.0998850876981487\n",
            "gb_step=18200, loss=0.0994345902828536\n",
            "gb_step=18300, loss=0.08397552924234333\n",
            "gb_step=18400, loss=0.09461567316313449\n",
            "VAL ACCURACY 0.3456221198156682\n",
            "val_loss 3.3830767471751773\n",
            "gb_step=18500, loss=0.05798799601308929\n",
            "gb_step=18600, loss=0.06247494161065333\n",
            "gb_step=18700, loss=0.04000052981611588\n",
            "gb_step=18800, loss=0.07477335149769715\n",
            "gb_step=18900, loss=0.08272149548671223\n",
            "gb_step=19000, loss=0.05229103217416196\n",
            "gb_step=19100, loss=0.08293636158872687\n",
            "gb_step=19200, loss=0.08827632901584366\n",
            "gb_step=19300, loss=0.07273503299291406\n",
            "gb_step=19400, loss=0.09517327311699773\n",
            "gb_step=19500, loss=0.053183523868428895\n",
            "gb_step=19600, loss=0.05654820800476955\n",
            "Saving model checkpoint to  content/output/checkpoint-19664\n",
            "VAL ACCURACY 0.3225806451612903\n",
            "val_loss 3.6995057822171664\n",
            "gb_step=19700, loss=0.08138550216870499\n",
            "gb_step=19800, loss=0.06638270513645693\n",
            "gb_step=19900, loss=0.08500198455092686\n",
            "gb_step=20000, loss=0.038250472917170555\n",
            "gb_step=20100, loss=0.06376513138242444\n",
            "gb_step=20200, loss=0.06834693220303961\n",
            "gb_step=20300, loss=0.0812629673162155\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b6160056b36b>\u001b[0m in \u001b[0;36mtrain_main\u001b[0;34m(start_global_step)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_global_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train finished, step: {}, loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-24062eb6fc7a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config, train_dataset, val_dataset, model, tokenizer, start_global_step)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training mode is expected to be boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 raise AttributeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_ParameterMeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Make `isinstance(t, Parameter)` return True for custom tensor instances that have the _is_param flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         return super().__instancecheck__(instance) or (\n\u001b[1;32m     10\u001b[0m             isinstance(instance, torch.Tensor) and getattr(instance, '_is_param', False))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False\n",
        "# Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias', 'lm_head.decoder.bias']\n",
        "# You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
        "# Loading cached file from content/tensor/roberta_256_train\n",
        "# Loading cached file from content/tensor/roberta_256_val\n",
        "# AdamW (\n",
        "# Parameter Group 0\n",
        "#     betas: (0.9, 0.98)\n",
        "#     correct_bias: True\n",
        "#     eps: 1e-06\n",
        "#     initial_lr: 1e-05\n",
        "#     lr: 0.0\n",
        "#     weight_decay: 0.01\n",
        "\n",
        "# Parameter Group 1\n",
        "#     betas: (0.9, 0.98)\n",
        "#     correct_bias: True\n",
        "#     eps: 1e-06\n",
        "#     initial_lr: 1e-05\n",
        "#     lr: 0.0\n",
        "#     weight_decay: 0.0\n",
        "# )\n",
        "# -- Start Training --\n",
        "#   Num examples =  4638\n",
        "#   Num Epochs =  10\n",
        "#   Batch size =  1\n",
        "#   Gradient Accumulation steps =  6\n",
        "#   Total optimization steps =  7730\n",
        "# gb_step=100, loss=1.3906832191348075\n",
        "# gb_step=200, loss=1.3830486480891704\n",
        "# gb_step=300, loss=1.3946657808125018\n",
        "# gb_step=400, loss=1.3937036837637424\n",
        "# gb_step=500, loss=1.38407785192132\n",
        "# gb_step=600, loss=1.3237384892255069\n",
        "# gb_step=700, loss=1.2902826748788356\n",
        "# Saving model checkpoint to  content/output/checkpoint-773\n",
        "# VAL ACCURACY 0.436\n",
        "# val_loss 1.24694089114666\n",
        "# gb_step=800, loss=1.2378022559173405\n",
        "# gb_step=900, loss=1.2037188726197927\n",
        "# gb_step=1000, loss=1.0709503892436623\n",
        "# gb_step=1100, loss=1.1575460922718048\n",
        "# gb_step=1200, loss=1.1075375059619545\n",
        "# gb_step=1300, loss=1.0915902483975515\n",
        "# gb_step=1400, loss=1.0937564730830491\n",
        "# gb_step=1500, loss=1.1201259839721025\n",
        "# Saving model checkpoint to  content/output/checkpoint-1546\n",
        "# VAL ACCURACY 0.562\n",
        "# val_loss 1.021248332247138\n",
        "# gb_step=1600, loss=0.8839860117039643\n",
        "# gb_step=1700, loss=0.6966540498952963\n",
        "# gb_step=1800, loss=0.7248349349077035\n",
        "# gb_step=1900, loss=0.7467363401993498\n",
        "# gb_step=2000, loss=0.6954545036122727\n",
        "# gb_step=2100, loss=0.8221353476736113\n",
        "# gb_step=2200, loss=0.688394755335903\n",
        "# gb_step=2300, loss=0.6831466681133316\n",
        "# Saving model checkpoint to  content/output/checkpoint-2319\n",
        "# VAL ACCURACY 0.606\n",
        "# val_loss 0.9276560444813222\n",
        "# gb_step=2400, loss=0.4219084879282173\n",
        "# gb_step=2500, loss=0.3300979009099092\n",
        "# gb_step=2600, loss=0.2725311021212656\n",
        "# gb_step=2700, loss=0.36256908578400726\n",
        "# gb_step=2800, loss=0.3331815189065719\n",
        "# gb_step=2900, loss=0.3602212211330743\n",
        "# gb_step=3000, loss=0.31294935808199625\n",
        "# Saving model checkpoint to  content/output/checkpoint-3092\n",
        "# VAL ACCURACY 0.612\n",
        "# val_loss 1.2056505223396505\n",
        "# gb_step=3100, loss=0.2996267224210169\n",
        "# gb_step=3200, loss=0.13064403417701215\n",
        "# gb_step=3300, loss=0.14489557868756947\n",
        "# gb_step=3400, loss=0.12651861046371324\n",
        "# gb_step=3500, loss=0.1562492121116611\n",
        "# gb_step=3600, loss=0.11562360857192289\n",
        "# gb_step=3700, loss=0.14775275781069014\n",
        "# gb_step=3800, loss=0.19922116898707828\n",
        "# Saving model checkpoint to  content/output/checkpoint-3865\n",
        "# VAL ACCURACY 0.606\n",
        "# val_loss 1.6527001306686906\n",
        "# gb_step=3900, loss=0.11783152809639887\n",
        "# gb_step=4000, loss=0.05724837024125918\n",
        "# gb_step=4100, loss=0.08328599952035347\n",
        "# gb_step=4200, loss=0.0944014540564649\n",
        "# gb_step=4300, loss=0.09052542202972745\n",
        "# gb_step=4400, loss=0.06593119219420714\n",
        "# gb_step=4500, loss=0.07895771362668257\n",
        "# gb_step=4600, loss=0.09590211741502572\n",
        "# Saving model checkpoint to  content/output/checkpoint-4638\n",
        "# VAL ACCURACY 0.608\n",
        "# val_loss 1.7362016987618958\n",
        "# gb_step=4700, loss=0.057499595947415404\n",
        "# gb_step=4800, loss=0.037112483877635896\n",
        "# gb_step=4900, loss=0.039515550059386444\n",
        "# gb_step=5000, loss=0.06370177432631863\n",
        "# gb_step=5100, loss=0.04252046505283943\n",
        "# gb_step=5200, loss=0.03971146982071787\n",
        "# gb_step=5300, loss=0.05540029381877048\n",
        "# gb_step=5400, loss=0.04560911384209703\n",
        "# Saving model checkpoint to  content/output/checkpoint-5411\n",
        "# VAL ACCURACY 0.632\n",
        "# val_loss 2.0236645980290984\n",
        "# gb_step=5500, loss=0.03800823604621201\n",
        "# gb_step=5600, loss=0.02870803069612066\n",
        "# gb_step=5700, loss=0.044941766361484954\n",
        "# gb_step=5800, loss=0.03474681099190548\n",
        "# gb_step=5900, loss=0.029943934856551096\n",
        "# gb_step=6000, loss=0.02984334486577609\n",
        "# gb_step=6100, loss=0.023299850600451463\n",
        "# Saving model checkpoint to  content/output/checkpoint-6184\n",
        "# VAL ACCURACY 0.62\n",
        "# val_loss 2.1258305217671833\n",
        "# gb_step=6200, loss=0.04583871823260324\n",
        "# gb_step=6300, loss=0.027574690634696707\n",
        "# gb_step=6400, loss=0.026231208402600716\n",
        "# gb_step=6500, loss=0.01809466736759987\n",
        "# gb_step=6600, loss=0.019695667388891707\n",
        "# gb_step=6700, loss=0.018579683440211738\n",
        "# gb_step=6800, loss=0.02311229538666339\n",
        "# gb_step=6900, loss=0.02025991700936629\n",
        "# Saving model checkpoint to  content/output/checkpoint-6957\n",
        "# VAL ACCURACY 0.638\n",
        "# val_loss 2.1296772076439283\n",
        "# gb_step=7000, loss=0.013128395172352612\n",
        "# gb_step=7100, loss=0.009796608216411186\n",
        "# gb_step=7200, loss=0.00953967658502279\n",
        "# gb_step=7300, loss=0.01439472481149096\n",
        "# gb_step=7400, loss=0.008181649746939001\n",
        "# gb_step=7500, loss=0.007883859690005011\n",
        "# gb_step=7600, loss=0.00978013759836358\n",
        "# gb_step=7700, loss=0.012991459028830832\n",
        "# Saving model checkpoint to  content/output/checkpoint-7730\n",
        "# VAL ACCURACY 0.63\n",
        "# val_loss 2.2396614357486646\n",
        "# Train finished, step: 7730, loss: 0.38654366853648475"
      ],
      "metadata": {
        "id": "0ScNBOc7PeUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(config, split=\"val\", checkpoint_name=''):\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    config.device = device\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.output_path + '/' + checkpoint_name)\n",
        "    model = RobertaForMultipleChoice.from_pretrained(config.output_path + '/' + checkpoint_name)\n",
        "\n",
        "    model.to(config.device)\n",
        "\n",
        "    dataset, features = load_dataset(config, tokenizer, split=split)\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=config.eval_batch_size,\n",
        "                                  collate_fn=collator)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"***** Running evaluation {} on {} *****\".format(split, checkpoint_name))\n",
        "    print(\"  Num examples =\", len(dataset))\n",
        "    print(\"  Batch size =\", config.eval_batch_size)\n",
        "\n",
        "    model.eval()\n",
        "    pred_list = []\n",
        "    prob_list = []\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\", dynamic_ncols=True):\n",
        "        batch = batch_to_device(batch, config.device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**batch)\n",
        "                probs = outputs[\"logits\"].softmax(dim=-1).detach().float().cpu()\n",
        "                prob, pred = probs.max(dim=-1)\n",
        "                pred_list.extend(pred.tolist())\n",
        "                prob_list.extend(prob.tolist())\n",
        "  \n",
        "    metric_log, results = model.get_eval_log(reset=True)\n",
        "    print(\"****** Evaluation Results ******\")\n",
        "    print(metric_log)\n",
        "    \n",
        "    prediction_file = os.path.join(config.output_path, \"{checkpoint_name}_eval_predictions.npy\")\n",
        "    np.save(prediction_file, pred_list)\n",
        "    json.dump(prob_list, open(os.path.join(config.output_path, \"{checkpoint_name}_eval_probs.json\"), \"w\"))\n",
        "    return results"
      ],
      "metadata": {
        "id": "-dFX9rYtW2pg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRp4snhwQaQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(config, checkpoint_name='checkpoint-19664')"
      ],
      "metadata": {
        "id": "gVEM5Ug6LcQG",
        "outputId": "80a2a53c-8b71-4cc1-d22e-f1621d980166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "Loading cached file from content/tensor/roberta_256_val\n",
            "***** Running evaluation val on checkpoint-19664 *****\n",
            "  Num examples = 651\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 651/651 [00:14<00:00, 44.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** Evaluation Results ******\n",
            "loss: 3.6995057822171664\tacc: 0.3225806451612903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 3.6995057822171664, 'acc': 0.3225806451612903}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "def make_archive(source, destination):\n",
        "        base = os.path.basename(destination)\n",
        "        name = base.split('.')[0]\n",
        "        format = base.split('.')[1]\n",
        "        archive_from = os.path.dirname(source)\n",
        "        archive_to = os.path.basename(source.strip(os.sep))\n",
        "        shutil.make_archive(name, format, archive_from, archive_to)\n",
        "        shutil.move('%s.%s'%(name,format), destination)\n",
        "\n",
        "make_archive('/content/content', '/content/drive/MyDrive/Thesis/Reclore/13march2023_res_optimizer_change.zip')"
      ],
      "metadata": {
        "id": "wZ9xw0PFPxgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SPmHwATQNxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}